=========== DATE :  ============
=========== nb heures :  ============
Planned :

Done :

Problems :

Questions :

Answers :


=========== DATE : 27.09.23 ============
=========== nb heures :  ============
Planned :
- adapt dataset to pointMLP method
- start an other method

Done :

Problems :

Questions :

Answers :



---------------------------^^^ ----------------------- ^^^ ------------
---------------------------||| Current questions above ||| ------------
-----------------------------------------------------------------------
=========== DATE : 26.09.23 ============
=========== nb heures : 4.0 ============
Planned :
- continue to try to make a model works
- learn how to manipulate pcd files

Done :
- manage to run the pointMLP method on original dataset
- managed to load and show pcd files
- automate pcd copies generation for clean dataset 


Problems :
- couldn't find the label on the .pcd file

Questions :
- would it be more efficient to store all the dataset in .h5 files?
- is there the label with the .pcd file or is it "blank"?
- can we get the label in the .pcd file?

Answers :


=========== DATE : 25.09.23 ============
=========== nb heures : 4.0 ============
Planned :
- create architecture
- learn how to make a library
- learn how to use the different models
- create data processing part
- continue making the obsidian note on wandb

Done :
- obsidian note made on python libraries
- a first version of the architecture is done
- the preprocess is going to be done differently for each model
- 

Problems :
- the different models are difficult to install. Getting a lot of different problems / incompatibility of library version / etc...

Questions :
- seems like a lot (all) the methods have been implemented on ubuntu. Would it be interesting that I install it or is it a lost of time for this project?
- 

Answers :



=========== DATE : 22.09.23 ============
=========== nb heures : 2.0 ============
Planned :
- Fine code for the 9 models
- Start looking into the online plateform "weights and biases"

Done :
- Found code for the 9 models
- Already created an account on wandb, started some tuto. Can be very usefull. Will need to include it in the architecture reflection and make some tests once a first model is opperational.

Problems :

Questions :
- Could the plateform "weigths and biases" be usefull for the testing of the different models?


Answers :



=========== DATE : 21.09.23 ============
=========== nb heures : 4.5 ============
Planned: 
- fine relevant literature about Graph Neural Network, Attention,..
- Documentation about graph Neural network
- Documentation about attention

Done :
- Found Point-GNN model (+ code) for object detection -> might be usefull for the second model
- Found Graph-CNN model (+ code)
- Found a survey paper from which a lot of interesting model need to be tested.
	- with the graph-CNN model, that is 8 different candidates

Problems:
- 

Questions:
- Would it be interesting to remove points from trees with high resolution in order to train it on lower resolution and find out the density of points from which the model looses accuracy?
	- model to do so -> Farthest Point Sampling (FPS)
- Instead of training one big model on data of different density, might be better to train multiple model with the same dataset at different densities (generated with FPS)
- First focus on implementing/testing the different methods or labelising data?

Answers:
- might be.
- might be.
	- will be usefull for later
- might be
- First find out which model released their code and then start the process of files. The labeling will come later once the utilitary to visualize samples is finished.


